{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1b2c3d4",
   "metadata": {},
   "source": [
    "# LinkedIn Job Data Cleaning Pipeline\n",
    "This notebook processes and cleans LinkedIn job posting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f6g7h8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import pandas as pd\n",
    "import re\n",
    "from langdetect import detect, LangDetectException\n",
    "from tqdm.notebook import tqdm\n",
    "from googletrans import Translator\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Initialize translator\n",
    "translator = Translator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "i9j0k1l2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "df = pd.read_excel(\"../data/raw/Final Dataset.xlsx\")\n",
    "print(f\"Loaded {len(df)} rows\")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9752283",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d0e8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Make all column names lowercase\n",
    "df.columns = df.columns.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca8b9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Clean the column (remove commas/whitespace)\n",
    "s = df['date'].astype(str).str.strip().str.replace(r',\\s*$', '', regex=True)\n",
    "\n",
    "# Try exact dd/mm/yyyy format first\n",
    "parsed = pd.to_datetime(s, format='%d/%m/%Y', errors='coerce')\n",
    "\n",
    "# For any remaining values (like 2024-09-09 00:00:00), do a flexible parse\n",
    "mask = parsed.isna()\n",
    "parsed[mask] = pd.to_datetime(s[mask], errors='coerce')\n",
    "\n",
    "# Assign back\n",
    "df['date'] = parsed\n",
    "\n",
    "print(f\"Parsed: {df['date'].notna().sum()} | Failed: {df['date'].isna().sum()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425968e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbbb140",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "q7r8s9t0",
   "metadata": {},
   "source": [
    "## Text Processing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "u1v2w3x4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Language Detection and Translation\n",
    "def detect_and_translate(text):\n",
    "    \"\"\"\n",
    "    Detects language and translates to English if needed.\n",
    "    Uses langdetect for detection and googletrans for translation.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Handle empty or non-string values\n",
    "        if not isinstance(text, str) or text.strip() == '':\n",
    "            return 'Not Provided'\n",
    "        \n",
    "        # Detect language\n",
    "        detected_lang = detect(text)\n",
    "        \n",
    "        # If not English, translate\n",
    "        if detected_lang != 'en':\n",
    "            translated = translator.translate(text, src=detected_lang, dest='en')\n",
    "            return translated.text\n",
    "        \n",
    "        return text\n",
    "    \n",
    "    except LangDetectException:\n",
    "        # If language detection fails, try translation anyway\n",
    "        try:\n",
    "            translated = translator.translate(text, dest='en')\n",
    "            return translated.text\n",
    "        except:\n",
    "            return 'Not Provided'\n",
    "    except Exception as e:\n",
    "        print(f\"Translation error: {e}\")\n",
    "        return 'Not Provided'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "y5z6a7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Extraction Functions\n",
    "def clean_html(text):\n",
    "    \"\"\"Remove HTML tags and clean text\"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return 'Not Provided'\n",
    "    \n",
    "    # Remove HTML tags\n",
    "    text = re.sub(r'<[^>]+>', '', text)\n",
    "    \n",
    "    # Remove extra whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    \n",
    "    # Decode HTML entities\n",
    "    text = text.replace('&nbsp;', ' ')\n",
    "    text = text.replace('&amp;', '&')\n",
    "    text = text.replace('&lt;', '<')\n",
    "    text = text.replace('&gt;', '>')\n",
    "    text = text.replace('&quot;', '\"')\n",
    "    \n",
    "    return text.strip()\n",
    "\n",
    "\n",
    "def clean_title(text):\n",
    "    \"\"\"Clean job title by removing salary info and extra content\"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return 'Not Provided'\n",
    "    \n",
    "    # Remove salary information\n",
    "    text = re.sub(r'[\\$£€₦₹]\\s?[\\d,]+.*', '', text)\n",
    "    \n",
    "    # Remove content after pipe or dash\n",
    "    text = re.sub(r'\\s*[-–|].*', '', text)\n",
    "    \n",
    "    return text.strip()\n",
    "\n",
    "\n",
    "def extract_tools(text):\n",
    "    \"\"\"Extract technical tools and technologies from text\"\"\"\n",
    "    tools = [\n",
    "        'Excel', 'SQL', 'Python', 'R', 'Tableau', 'Power BI', 'Looker', \n",
    "        'SAS', 'SPSS', 'Jupyter', 'Pandas', 'NumPy', 'Matplotlib', \n",
    "        'Seaborn', 'Snowflake', 'AWS', 'Google Analytics', 'BigQuery', \n",
    "        'Hadoop', 'Spark', 'Django', 'Flask', 'Git', 'GitHub', 'Docker', \n",
    "        'Kubernetes', 'PySpark', 'Airflow', 'Azure', 'GCP', 'Redshift',\n",
    "        'DAX', 'ETL', 'API', 'PostgreSQL', 'MySQL', 'MongoDB'\n",
    "    ]\n",
    "    \n",
    "    if not isinstance(text, str):\n",
    "        return 'Not Provided'\n",
    "    \n",
    "    found = []\n",
    "    for tool in tools:\n",
    "        pattern = r'\\b' + re.escape(tool) + r'\\b'\n",
    "        if re.search(pattern, text, re.IGNORECASE):\n",
    "            found.append(tool)\n",
    "    \n",
    "    return ', '.join(found) if found else 'Not Provided'\n",
    "\n",
    "\n",
    "def extract_education(text):\n",
    "    \"\"\"Extract education level requirements\"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return 'Not Provided'\n",
    "\n",
    "    education_keywords = {\n",
    "        r\"bachelor[''s]*|b\\.?s\\.?c\\.?|undergraduate\": \"Bachelor's\",\n",
    "        r\"master[''s]*|m\\.?s\\.?c\\.?|postgraduate\": \"Master's\",\n",
    "        r\"ph[.]?d|doctorate|doctoral\": \"PhD\",\n",
    "        r\"associate degree|associates\": \"Associate Degree\",\n",
    "        r\"diploma|certification\": \"Diploma\"\n",
    "    }\n",
    "\n",
    "    found_levels = []\n",
    "    for pattern, label in education_keywords.items():\n",
    "        if re.search(pattern, text, re.IGNORECASE):\n",
    "            found_levels.append(label)\n",
    "\n",
    "    return ', '.join(sorted(set(found_levels))) if found_levels else 'Not Provided'\n",
    "\n",
    "\n",
    "def extract_experience_years(text):\n",
    "    \"\"\"Extract years of experience required\"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return 'Not Provided'\n",
    "    \n",
    "    patterns = [\n",
    "        r'(\\d+)\\+?\\s*(?:years?|yrs?)(?:\\s+of)?\\s+experience',\n",
    "        r'minimum\\s+(?:of\\s+)?(\\d+)\\s*(?:years?|yrs?)',\n",
    "        r'at\\s+least\\s+(\\d+)\\s*(?:years?|yrs?)',\n",
    "        r'(\\d+)\\s*(?:to|-)\\s*(\\d+)\\s*(?:years?|yrs?)'\n",
    "    ]\n",
    "\n",
    "    for pattern in patterns:\n",
    "        match = re.search(pattern, text, re.IGNORECASE)\n",
    "        if match:\n",
    "            try:\n",
    "                years = int(match.group(1))\n",
    "                if years <= 15:  # Reasonable upper limit\n",
    "                    return str(years)\n",
    "            except:\n",
    "                continue\n",
    "    \n",
    "    return 'Not Provided'\n",
    "\n",
    "\n",
    "def extract_job_type(text):\n",
    "    \"\"\"Extract job type (Full Time, Part Time, etc.)\"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return 'Not Provided'\n",
    "\n",
    "    job_types = {\n",
    "        r'full[-\\s]?time': 'Full Time',\n",
    "        r'part[-\\s]?time': 'Part Time',\n",
    "        r'contract(?:ual)?': 'Contract',\n",
    "        r'intern(?:ship)?': 'Internship',\n",
    "        r'freelance|freelancer': 'Freelance',\n",
    "        r'temporary|temp': 'Temporary'\n",
    "    }\n",
    "    \n",
    "    for pattern, job_type in job_types.items():\n",
    "        if re.search(pattern, text, re.IGNORECASE):\n",
    "            return job_type\n",
    "    \n",
    "    return 'Not Provided'\n",
    "\n",
    "\n",
    "def extract_country(place):\n",
    "    \"\"\"Extract country from location string\"\"\"\n",
    "    if not isinstance(place, str) or place.strip() == '':\n",
    "        return 'Not Provided'\n",
    "    \n",
    "    # Assuming country is the last part after comma\n",
    "    parts = place.split(',')\n",
    "    country = parts[-1].strip()\n",
    "    \n",
    "    return country if country else 'Not Provided'\n",
    "\n",
    "\n",
    "def extract_remote_onsite(text):\n",
    "    \"\"\"Determine if job is remote, hybrid, or onsite\"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return 'Not Provided'\n",
    "\n",
    "    if re.search(r'\\bremote\\b', text, re.IGNORECASE):\n",
    "        return 'Remote'\n",
    "    elif re.search(r'\\bhybrid\\b', text, re.IGNORECASE):\n",
    "        return 'Hybrid'\n",
    "    elif re.search(r'on[-\\s]?site|office', text, re.IGNORECASE):\n",
    "        return 'Onsite'\n",
    "    \n",
    "    return 'Not Provided'\n",
    "\n",
    "\n",
    "def extract_experience_level(text):\n",
    "    \"\"\"Extract experience level (Senior, Mid-Level, Junior, etc.)\"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return 'Not Provided'\n",
    "\n",
    "    levels = {\n",
    "        r'\\b(senior|lead|principal|staff)\\b': 'Senior',\n",
    "        r'\\b(mid[-\\s]?level|intermediate)\\b': 'Mid-Level',\n",
    "        r'\\b(junior|entry[-\\s]?level|associate)\\b': 'Junior',\n",
    "        r'\\b(intern|graduate|trainee)\\b': 'Intern'\n",
    "    }\n",
    "    \n",
    "    for pattern, level in levels.items():\n",
    "        if re.search(pattern, text, re.IGNORECASE):\n",
    "            return level\n",
    "    \n",
    "    return 'Not Provided'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e76ffa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c9d0e1f2",
   "metadata": {},
   "source": [
    "## Apply Cleaning Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f16fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare Text Columns\n",
    "df['title'] = df['title'].fillna('').astype(str)\n",
    "df['description'] = df['description'].fillna('').astype(str)\n",
    "df['place'] = df['place'].fillna('').astype(str)\n",
    "\n",
    "print(\"Text columns prepared\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e078ea87",
   "metadata": {},
   "source": [
    "## Translate Non-English Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb32ceb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Safe translation wrapper\n",
    "def safe_translate(text):\n",
    "    try:\n",
    "        return detect_and_translate(text)\n",
    "    except:\n",
    "        return text\n",
    "\n",
    "def translate_columns_in_batches_manual(df, columns, batch_size=500, sleep_sec=1):\n",
    "    for col in columns:\n",
    "        print(f\"Translating '{col}' in batches...\")\n",
    "        translated = []\n",
    "        total = len(df)\n",
    "        for start in range(0, total, batch_size):\n",
    "            end = min(start + batch_size, total)\n",
    "            batch = df[col].iloc[start:end]\n",
    "            # Manual row-by-row translation with tqdm\n",
    "            batch_translated = []\n",
    "            for text in tqdm(batch, desc=f\"{col} rows {start}-{end}\"):\n",
    "                batch_translated.append(safe_translate(text))\n",
    "            translated.extend(batch_translated)\n",
    "            time.sleep(sleep_sec)  # avoid API rate limits\n",
    "        df[col + '_translated'] = pd.Series(translated, index=df.index)\n",
    "    print(\"All translations complete!\")\n",
    "    return df\n",
    "\n",
    "# Usage\n",
    "df = translate_columns_in_batches_manual(df, columns=['title', 'description'], batch_size=500, sleep_sec=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10159953",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316839e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv(\"translated_jobs.csv\", index=False)\n",
    "\n",
    "print(\"Data saved to 'translated_jobs.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "k7l8m9n0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean HTML from translated description\n",
    "print(\"Cleaning HTML from descriptions...\")\n",
    "df['description_clean'] = df['description_translated'].apply(clean_html)\n",
    "\n",
    "print(\"HTML cleaning complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943bd7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean Title (use translated version)\n",
    "df['title_clean'] = df['title_translated'].apply(clean_title)\n",
    "print(\"Titles cleaned\")\n",
    "df[['title', 'title_translated', 'title_clean']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0d411c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine Text (use translated and cleaned text)\n",
    "df['combined_text'] = df['title_translated'] + ' ' + df['description_clean']\n",
    "print(\"Combined text created\")\n",
    "df['combined_text'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "s5t6u7v8",
   "metadata": {},
   "source": [
    "## Extract Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "w9x0y1z2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Extracting tools...\")\n",
    "df['tools'] = df['combined_text'].apply(extract_tools)\n",
    "df[['tools']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b4c5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Extracting education requirements...\")\n",
    "df['education'] = df['combined_text'].apply(extract_education)\n",
    "df[['education']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f8g9h0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Extracting experience years...\")\n",
    "df['experience_years'] = df['combined_text'].apply(extract_experience_years)\n",
    "df[['experience_years']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "i1j2k3l4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Extracting experience level...\")\n",
    "df['experience_level'] = df['combined_text'].apply(extract_experience_level)\n",
    "df[['experience_level']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "m5n6o7p8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Extracting job type...\")\n",
    "df['job_type'] = df['combined_text'].apply(extract_job_type)\n",
    "df[['job_type']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "q9r0s1t2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Extracting work arrangement...\")\n",
    "df['remote_onsite'] = df['combined_text'].apply(extract_remote_onsite)\n",
    "df[['remote_onsite']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "u3v4w5x6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Extracting country...\")\n",
    "df['country'] = df['place'].apply(extract_country)\n",
    "df[['place', 'country']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "y7z8a9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Feature extraction complete!\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d2e3f4",
   "metadata": {},
   "source": [
    "## Filter for Analytics Roles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "g5h6i7j8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def keep_analytics_roles(df, title_column='title_clean'):\n",
    "    \"\"\"\n",
    "    Filters dataset to keep only analytics-focused job titles.\n",
    "    Includes: analyst, analytics, BI specialist, SQL developer, etc.\n",
    "    Excludes: non-relevant dev/engineering roles unless in whitelist.\n",
    "    \"\"\"\n",
    "    df[title_column] = df[title_column].str.lower()\n",
    "\n",
    "    # Include if title contains any of these\n",
    "    must_include = [\n",
    "        'analyst', 'analytics',\n",
    "        'analytics engineer', 'sql developer', 'bi developer',\n",
    "        'bi specialist', 'bi analyst', 'bi consultant', 'bi engineer',\n",
    "        'business intelligence'\n",
    "    ]\n",
    "\n",
    "    # Exclude these unless in whitelist\n",
    "    must_exclude = [\n",
    "        'machine learning', 'ml engineer', 'ai engineer', \n",
    "        'data scientist', 'solution architect', 'cloud engineer',\n",
    "        'devops', 'support engineer', 'qa', 'system admin',\n",
    "        'game', 'unity', 'security', 'salesforce', 'frontend',\n",
    "        'backend', 'web developer', 'test engineer', 'researcher'\n",
    "    ]\n",
    "\n",
    "    # Whitelist exceptions\n",
    "    allowed_roles = [\n",
    "        'sql developer', 'analytics engineer', 'bi developer',\n",
    "        'bi analyst', 'bi specialist', 'bi consultant', 'bi engineer',\n",
    "        'data analyst', 'business analyst', 'reporting analyst'\n",
    "    ]\n",
    "\n",
    "    def is_valid_title(title):\n",
    "        # Must match at least one include term\n",
    "        include = any(kw in title for kw in must_include)\n",
    "        \n",
    "        # Exclude only if excluded term present AND not in allowed roles\n",
    "        exclude = any(\n",
    "            bad in title and not any(allowed in title for allowed in allowed_roles)\n",
    "            for bad in must_exclude\n",
    "        )\n",
    "        \n",
    "        return include and not exclude\n",
    "\n",
    "    filtered_df = df[df[title_column].apply(is_valid_title)].copy()\n",
    "    print(f\"Filtered from {len(df)} to {len(filtered_df)} analytics roles\")\n",
    "    \n",
    "    return filtered_df\n",
    "\n",
    "df_final = keep_analytics_roles(df, title_column='title_clean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "k9l0m1n2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View sample of filtered data\n",
    "df_final[['title_clean', 'experience_level', 'tools']].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "o3p4q5r6",
   "metadata": {},
   "source": [
    "## Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "s7t8u9v0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select relevant columns for export\n",
    "columns_to_export = [\n",
    "    'job_id', 'title', 'title_clean', 'company', 'place', 'country',\n",
    "    'date', 'description_clean', 'link', 'tools', 'education', \n",
    "    'experience_years', 'experience_level', 'job_type', 'remote_onsite'\n",
    "]\n",
    "\n",
    "# Only keep columns that exist\n",
    "columns_to_export = [col for col in columns_to_export if col in df_final.columns]\n",
    "\n",
    "df_export = df_final[columns_to_export].copy()\n",
    "\n",
    "# Export to Excel\n",
    "df_export.to_excel('../data/processed/linkedin_data_final.xlsx', index=False)\n",
    "print(f\"Exported {len(df_export)} rows to linkedin_data_final.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "w1x2y3z4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display summary statistics\n",
    "print(\"\\n=== Dataset Summary ===\")\n",
    "print(f\"Total rows: {len(df_export)}\")\n",
    "print(f\"Date range: {df_export['date'].min()} to {df_export['date'].max()}\")\n",
    "print(f\"\\nTop 10 Tools:\")\n",
    "print(df_export['tools'].str.split(', ').explode().value_counts().head(10))\n",
    "print(f\"\\nJob Type Distribution:\")\n",
    "print(df_export['job_type'].value_counts())\n",
    "print(f\"\\nExperience Level Distribution:\")\n",
    "print(df_export['experience_level'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b6c7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display final dataset\n",
    "df_export.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
